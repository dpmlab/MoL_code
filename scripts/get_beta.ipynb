{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import deepdish as dd\n",
    "import string\n",
    "try:\n",
    "    os.chdir('/data/MoL_clean/scripts')\n",
    "except:\n",
    "    pass\n",
    "import util\n",
    "# import GLM_helper as gh\n",
    "\n",
    "import scipy.stats as stats\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2subj = {\"sub-01\":\"subj001\", \"sub-02\":\"subj002\",\"sub-03\":\"subj003\",\"sub-04\":\"subj005\",\n",
    "              \"sub-05\":\"subj006\", \"sub-06\":\"subj007\", \"sub-07\":\"subj008\", \"sub-08\":\"subj009\", \n",
    "           \"sub-09\":\"subj010\",\"sub-10\":\"subj011\",\"sub-11\":\"subj013\", \"sub-12\":\"subj014\", \n",
    "            \"sub-13\":\"subj017\", \"sub-14\":\"subj018\", \"sub-15\":\"subj019\", \"sub-16\":\"subj020\",\n",
    "           \"sub-17\":\"subj021\", \"sub-18\":\"subj022\", \"sub-19\":\"subj023\", \"sub-20\":\"subj024\",'sub-21':'subj025',\n",
    "           'sub-22':'subj026','sub-23':'subj027','sub-24':'subj029','sub-25':'subj031',\n",
    "           'sub-101':'subj101', 'sub-102':'subj102', 'sub-103':'subj103', 'sub-105':'subj105','sub-107':'subj107','sub-108':'subj108'}\n",
    "\n",
    "ses2w = {\"ses-01\":\"W2\", \"ses-02\":\"W4D1\", \"ses-03\":\"W4D2\"}\n",
    "\n",
    "\n",
    "nv = 40962\n",
    "\n",
    "subjects = ['sub-%.2d'%s for s in range(1,26)]\n",
    "sessions = ['ses-%.2d'%s for s in range(1,3)]\n",
    "runs = ['run-%.2d'%s for s in range(1,3)]\n",
    "TR = 1.5\n",
    "nTRs = {'Item':302, 'Loci':302, 'Encode':355}\n",
    "\n",
    "nTRs_w4d2 = {'Item': 156, 'Loci': 156, 'Encode': 182}\n",
    "SL_lh = list(dd.io.load('SLlist_verydense.lh.h5').values())\n",
    "SL_rh = list(dd.io.load('SLlist_verydense.rh.h5').values())\n",
    "\n",
    "SLlist = {'L':SL_lh, \"R\": SL_rh}\n",
    "nSL_L = len(SLlist['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting design matrix for encoding, item, and loci task\n",
    "def get_design(task, num_TR, num_item=40, special=None):\n",
    "    em = np.zeros((int(num_TR*1.5)+1,num_item))\n",
    "    for index in range(num_item):\n",
    "        if task == 'item' or task == 'loci':\n",
    "            # item_task_structure: 1 sec fixation cross + 5 sec just item + 5 sec animate/inanimate judgement\n",
    "            em[index*11+1:(index+1)*11,index]=1\n",
    "        elif task == 'encoding':\n",
    "            # encode_task_structure: 1 sec fixation cross + 12 sec encode \n",
    "            em[index*13+1:(index+1)*13,index]=1\n",
    "\n",
    "    # refer to a bug in the experiment with the first few subjects where one of the loci trial was very long,\n",
    "    # affect about 3 subjects.\n",
    "    if special == 'long_loci':\n",
    "        em[44:65,4] = 1\n",
    "        em = np.concatenate((em[:,:5],em[:,6:]),axis=1)\n",
    "\n",
    "    \n",
    "    dm = util.regressor_to_TR(em, TR, num_TR) \n",
    "    \n",
    "\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve design matrix with fMRI data\n",
    "def deconv(V, design):\n",
    "    regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "    regr.fit(design, np.nan_to_num(V.T))\n",
    "    return regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_dm = get_design('loci', nTRs['Loci'])\n",
    "item_dm = get_design('item', nTRs['Item'])\n",
    "loci_special = get_design('loci', nTRs['Loci'], special='long_loci')\n",
    "encode_dm = get_design('encoding', nTRs['Encode'])\n",
    "dms = {'Loci':loci_dm, 'Item':item_dm, 'Encode':encode_dm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['sub-%.2d'%s for s in range(1,26)]\n",
    "\n",
    "for sub in subjects:\n",
    "    for ses in sessions:\n",
    "        for task in ['Loci','Item']:\n",
    "            for i, run in enumerate(runs):\n",
    "                    fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "                    rh = np.array(fmri_file[f'{task}_{run}']['R'])\n",
    "                    lh = np.array(fmri_file[f'{task}_{run}']['L'])\n",
    "                    ah = np.array(fmri_file[f'{task}_{run}']['anterior_hipp'])\n",
    "                    ph = np.array(fmri_file[f'{task}_{run}']['posterior_hipp'])\n",
    "                    hippo = np.array(fmri_file[f'{task}_{run}']['hippo'])\n",
    "                    ah_group = np.array(fmri_file[f'{task}_{run}']['anterior_hipp_group'])\n",
    "                    ph_group = np.array(fmri_file[f'{task}_{run}']['posterior_hipp_group'])\n",
    "                    hippo_group = np.array(fmri_file[f'{task}_{run}']['hippo_group'])\n",
    "                    dm = dms[task]\n",
    "                    if task =='Loci':\n",
    "                        if (sub == 'sub-02' and ses == 'ses-01') or (sub == 'sub-04' and ses == 'ses-01') or (sub == 'sub-03' and ses=='ses-01' and i == 0): \n",
    "                            dm = loci_special                        \n",
    "                    lh_beta = deconv(lh, dm)\n",
    "                    rh_beta = deconv(rh, dm)          \n",
    "                    ah_beta = deconv(ah, dm)         \n",
    "                    ph_beta =  deconv(ph, dm)   \n",
    "                    hippo_beta = deconv(hippo, dm)\n",
    "                    ah_group_beta = deconv(ah_group, dm)\n",
    "                    ph_group_beta = deconv(ph_group, dm)\n",
    "                    hippo_group_beta = deconv(hippo_group, dm)  \n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_lh_beta.txt'%(task.lower(),sub,ses,run), lh_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_rh_beta.txt'%(task.lower(),sub,ses,run), rh_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ah_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ph_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_beta.txt'%(task.lower(),sub,ses,run), hippo_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ah_group_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ph_group_beta)\n",
    "                    np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_group_beta.txt'%(task.lower(),sub,ses,run), hippo_group_beta)\n",
    "\n",
    "\n",
    "        task = 'Encode'\n",
    "        try: \n",
    "            run = 'run-02'\n",
    "            fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "        except:\n",
    "             run = 'run-01'\n",
    "             fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "        rh = np.array(fmri_file[f'{task}_{run}']['R'])\n",
    "        lh = np.array(fmri_file[f'{task}_{run}']['L'])\n",
    "        ah = np.array(fmri_file[f'{task}_{run}']['anterior_hipp'])\n",
    "        ph = np.array(fmri_file[f'{task}_{run}']['posterior_hipp'])\n",
    "        lh_beta = deconv(lh, dms[task])\n",
    "        rh_beta = deconv(rh, dms[task])\n",
    "        ah_beta = deconv(ah, dms[task])         \n",
    "        ph_beta =  deconv(ph, dms[task])   \n",
    "        hippo_beta = deconv(hippo, dm)\n",
    "        ah_group_beta = deconv(ah_group, dm)\n",
    "        ph_group_beta = deconv(ph_group, dm)\n",
    "        hippo_group_beta = deconv(hippo_group, dm)  \n",
    "        \n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_lh_beta.txt'%(task.lower(),sub,ses,run), lh_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_rh_beta.txt'%(task.lower(),sub,ses,run), rh_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ah_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ph_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_beta.txt'%(task.lower(),sub,ses,run), hippo_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ah_group_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ph_group_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_group_beta.txt'%(task.lower(),sub,ses,run), hippo_group_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_design_recall(recall_sheet, num_TR):\n",
    "    # create event matrix for retrieval. \n",
    "    recall_em = np.zeros((int(num_TR*1.5),len(recall_sheet)))\n",
    "    # correct_recall_em = recall_em.copy()\n",
    "    # incorrect_recall_em = recall_em.copy()\n",
    "    used_idx = []\n",
    "    for i in range(len(recall_sheet)):\n",
    "        recall_em[int(np.nan_to_num(recall_sheet['start_time'][i])):int(np.nan_to_num(recall_sheet['end_time'][i])),i]+=1\n",
    "        # if int(np.nan_to_num(recall_sheet['start_time'][i])) == int(np.nan_to_num(recall_sheet['end_time'][i])):\n",
    "        #     used_idx.append(i)\n",
    "    non_zero_columns = ~(recall_em==0).all(axis=0)\n",
    "\n",
    "    recall_em = recall_em[:,non_zero_columns]\n",
    "\n",
    "    dm = util.regressor_to_TR(recall_em, TR, num_TR) \n",
    "    \n",
    "    return dm\n",
    "\n",
    "\n",
    "for sub in subjects:\n",
    "    for ses in sessions:\n",
    "        task = 'Retrieve'\n",
    "        run = 'run-01'\n",
    "        fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "        rh = np.array(fmri_file[task+'_'+run]['R'])\n",
    "        lh = np.array(fmri_file[task+'_'+run]['L'])\n",
    "        ah = np.array(fmri_file[f'{task}_{run}']['anterior_hipp'])\n",
    "        ph = np.array(fmri_file[f'{task}_{run}']['posterior_hipp'])\n",
    "        hippo = np.array(fmri_file[f'{task}_{run}']['hippo'])\n",
    "        ah_group = np.array(fmri_file[f'{task}_{run}']['anterior_hipp_group'])\n",
    "        ph_group = np.array(fmri_file[f'{task}_{run}']['posterior_hipp_group'])\n",
    "        hippo_group = np.array(fmri_file[f'{task}_{run}']['hippo_group'])\n",
    "        recall_sheet = pd.read_excel('../sheets/%s_recallperformance.xlsx'%sub2subj[sub], sheet_name=ses2w[ses].lower())\n",
    "        \n",
    "        lh_beta = deconv(lh, get_design_recall(recall_sheet, lh.shape[1]))\n",
    "        rh_beta = deconv(rh, get_design_recall(recall_sheet, rh.shape[1]))\n",
    "\n",
    "        \n",
    "        ah_beta = deconv(ah,get_design_recall(recall_sheet, ah.shape[1])) \n",
    "        ph_beta = deconv(ph,get_design_recall(recall_sheet, ph.shape[1])) \n",
    "        hippo_beta = deconv(hippo,get_design_recall(recall_sheet, hippo.shape[1]))\n",
    "        ah_group_beta = deconv(ah_group,get_design_recall(recall_sheet, ah_group.shape[1]))\n",
    "        ph_group_beta = deconv(ph_group,get_design_recall(recall_sheet, ph_group.shape[1]))\n",
    "        hippo_group_beta = deconv(hippo_group,get_design_recall(recall_sheet, hippo_group.shape[1]))\n",
    "\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_lh_beta.txt'%(task.lower(),sub,ses,run), lh_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_rh_beta.txt'%(task.lower(),sub,ses,run), rh_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ah_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ph_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_beta.txt'%(task.lower(),sub,ses,run), hippo_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ah_group_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ph_group_beta)\n",
    "        np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_group_beta.txt'%(task.lower(),sub,ses,run), hippo_group_beta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTRs_w4d2 = {'Item': 156, 'Loci': 156, 'Encode': 182}\n",
    "\n",
    "loci_dm_w4d2 = get_design('loci', nTRs_w4d2['Loci'],20)\n",
    "item_dm_w4d2  = get_design('item', nTRs_w4d2['Item'],20)\n",
    "encode_dm_w4d2  = get_design('encoding', nTRs_w4d2['Encode'],20)\n",
    "dms_w4d2 =  {'Loci':loci_dm_w4d2, 'Item':item_dm_w4d2, 'Encode':encode_dm_w4d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['sub-%.2d'%s for s in range(1,26)]\n",
    "\n",
    "for sub in subjects:\n",
    "    ses = 'ses-03'\n",
    "    for task in ['Loci','Item']:\n",
    "        for i, run in enumerate(runs):\n",
    "                fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "                dm = dms_w4d2[task]                     \n",
    "                rh = np.array(fmri_file[f'{task}_{run}']['R'])\n",
    "                lh = np.array(fmri_file[f'{task}_{run}']['L'])\n",
    "                lh_beta = deconv(lh, dm)\n",
    "                rh_beta = deconv(rh, dm)                 \n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_lh_beta.txt'%(task.lower(),sub,ses,run), lh_beta)\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_rh_beta.txt'%(task.lower(),sub,ses,run), rh_beta)\n",
    "                ah = np.array(fmri_file[f'{task}_{run}']['anterior_hipp'])\n",
    "                ph = np.array(fmri_file[f'{task}_{run}']['posterior_hipp'])\n",
    "                hippo = np.array(fmri_file[f'{task}_{run}']['hippo'])\n",
    "                ah_group = np.array(fmri_file[f'{task}_{run}']['anterior_hipp_group'])\n",
    "                ph_group = np.array(fmri_file[f'{task}_{run}']['posterior_hipp_group'])\n",
    "                hippo_group = np.array(fmri_file[f'{task}_{run}']['hippo_group'])\n",
    "\n",
    "                ah_beta = deconv(ah, dm)         \n",
    "                ph_beta =  deconv(ph, dm) \n",
    "                hippo_beta = deconv(hippo, dm)\n",
    "                ah_group_beta = deconv(ah_group, dm)\n",
    "                ph_group_beta = deconv(ph_group, dm)\n",
    "                hippo_group_beta = deconv(hippo_group, dm)\n",
    "\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ah_beta)\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ph_beta)\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_beta.txt'%(task.lower(),sub,ses,run), hippo_beta)\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ah_group_beta)\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ph_group_beta)\n",
    "                np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_group_beta.txt'%(task.lower(),sub,ses,run), hippo_group_beta)\n",
    "    task = 'Encode'\n",
    "    try: \n",
    "        run = 'run-02'\n",
    "        fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "    except:\n",
    "            run = 'run-01'\n",
    "            fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "    rh = np.array(fmri_file[f'{task}_{run}']['R'])\n",
    "    lh = np.array(fmri_file[f'{task}_{run}']['L'])\n",
    "    dm = dms_w4d2[task]\n",
    "    lh_beta = deconv(lh, dm)\n",
    "    rh_beta = deconv(rh, dm)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_lh_beta.txt'%(task.lower(),sub,ses,run), lh_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_rh_beta.txt'%(task.lower(),sub,ses,run), rh_beta)\n",
    "    \n",
    "    \n",
    "    ah = np.array(fmri_file[f'{task}_{run}']['anterior_hipp'])\n",
    "    ph = np.array(fmri_file[f'{task}_{run}']['posterior_hipp'])\n",
    "    hippo = np.array(fmri_file[f'{task}_{run}']['hippo'])\n",
    "    ah_group = np.array(fmri_file[f'{task}_{run}']['anterior_hipp_group'])\n",
    "    ph_group = np.array(fmri_file[f'{task}_{run}']['posterior_hipp_group'])\n",
    "    hippo_group = np.array(fmri_file[f'{task}_{run}']['hippo_group'])\n",
    "\n",
    "    ah_beta = deconv(ah, dm)         \n",
    "    ph_beta =  deconv(ph, dm) \n",
    "    hippo_beta = deconv(hippo, dm)\n",
    "    ah_group_beta = deconv(ah_group, dm)\n",
    "    ph_group_beta = deconv(ph_group, dm)\n",
    "    hippo_group_beta = deconv(hippo_group, dm)\n",
    "\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ah_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ph_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_beta.txt'%(task.lower(),sub,ses,run), hippo_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ah_group_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ph_group_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_group_beta.txt'%(task.lower(),sub,ses,run), hippo_group_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for sub in subjects:\n",
    "    ses = 'ses-03'\n",
    "    task = 'Retrieve'\n",
    "    run = 'run-01'\n",
    "    fmri_file = h5py.File('../preprocessed/%s_%s_%s_%s.h5'%(sub,ses,task,run),'r')\n",
    "    rh = np.array(fmri_file[task+'_'+run]['R'])\n",
    "    lh = np.array(fmri_file[task+'_'+run]['L'])\n",
    "    recall_sheet = pd.read_excel('../sheets/%s_recallperformance.xlsx'%sub2subj[sub], sheet_name=ses2w[ses].lower())\n",
    "    lh_beta = deconv(lh, get_design_recall(recall_sheet, lh.shape[1]))\n",
    "    rh_beta = deconv(rh, get_design_recall(recall_sheet, rh.shape[1]))\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_lh_beta.txt'%(task.lower(),sub,ses,run), lh_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_rh_beta.txt'%(task.lower(),sub,ses,run), rh_beta)\n",
    "    ah = np.array(fmri_file[f'{task}_{run}']['anterior_hipp'])\n",
    "    ph = np.array(fmri_file[f'{task}_{run}']['posterior_hipp'])\n",
    "    hippo = np.array(fmri_file[f'{task}_{run}']['hippo'])\n",
    "    ah_group = np.array(fmri_file[f'{task}_{run}']['anterior_hipp_group'])\n",
    "    ph_group = np.array(fmri_file[f'{task}_{run}']['posterior_hipp_group'])\n",
    "    hippo_group = np.array(fmri_file[f'{task}_{run}']['hippo_group'])\n",
    "\n",
    "\n",
    "    ah_beta = deconv(ah, get_design_recall(recall_sheet, ah.shape[1]))         \n",
    "    ph_beta =  deconv(ph, get_design_recall(recall_sheet, ph.shape[1])) \n",
    "    hippo_beta = deconv(hippo, get_design_recall(recall_sheet, hippo.shape[1]))\n",
    "    ah_group_beta = deconv(ah_group, get_design_recall(recall_sheet, ah_group.shape[1]))\n",
    "    ph_group_beta = deconv(ph_group, get_design_recall(recall_sheet, ph_group.shape[1]))\n",
    "    hippo_group_beta = deconv(hippo_group, get_design_recall(recall_sheet, hippo_group.shape[1]))\n",
    "\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ah_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_beta.txt'%(task.lower(),sub,ses,run), ph_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_beta.txt'%(task.lower(),sub,ses,run), hippo_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_anterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ah_group_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_posterior_hipp_group_beta.txt'%(task.lower(),sub,ses,run), ph_group_beta)\n",
    "    np.savetxt('../outputs/betas/%s/%s_%s_%s_hippo_group_beta.txt'%(task.lower(),sub,ses,run), hippo_group_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Venv Environment",
   "language": "python",
   "name": "venv"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
